{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (Spyder)",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "TicTacToe-I.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-F6g8jHn7Q4"
      },
      "source": [
        "# Multi-agent Reinforcement Learning using PettingZoo: Tic-tac-toe example part I\n",
        "\n",
        "*Gertjan Verhoeven*\n",
        "\n",
        "*March 2021*"
      ],
      "id": "s-F6g8jHn7Q4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35NHsNK6n7Q7"
      },
      "source": [
        "In this notebook, we will take our first steps into the exciting world of **multi-agent reinforcement learning**. The simplest approach to multi-agent learning is to have the agents learn independently from each other, without having knowledge of each other. From the perspective of the learning agent, the other agents are simply part of the environment. (Literature: Littman 1994, Busoniu 2010).\n",
        "\n",
        "The notebook uses [PettingZoo](https://www.pettingzoo.ml), a Python library for conducting research in multi-agent reinforcement learning. It's akin to a multi-agent version of OpenAI's Gym library. \n",
        "\n",
        "PettingZoo has a large collection of environments (games) available, including Tic-Tac-Toe. We already experimented with Tic-Tac-Toe as part of the introduction chapter of Sutton and Barto. Tic-Tac-Toe therefore seems a natural starting point to start with multi-agent learning.\n",
        "\n",
        "Before we can start with PettingZoo, we first need to learn about the concept behind the package, which is to model each game as **Agent Environment Cycle (AEC)** games.\n"
      ],
      "id": "35NHsNK6n7Q7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygPUCdhan7Q9"
      },
      "source": [
        "# Agent Environment Cycle (AEC) games\n",
        "\n",
        "From [the paper](https://arxiv.org/abs/2009.13051) by Justin Terry et al:\n",
        "\n",
        ">The  base  component  of  an  AEC  game  is  a  **changeable  list of agents**.  After the first agent in the list acts, the environment can “act” (allowing agents’ observations to be updated), or the next designated agent can act (skipping environment turns are how truly simultaneous games are depicted). This process continues indefinitely.  \n",
        "\n",
        ">As  for  reward,  after  every  agent  takes  a  turn  a  “partial” reward is emitted to every other agent. The reward associated with a single action performed by an agent is the total of all the partial rewards following that action and before the agent’s next turn (until this point, the reward is not fully defined).   \n",
        "\n",
        ">Different aspects of a game will be responsible for different portions of reward. As shown in [this paper], thinking about rewards in this atomized manner instead of lumping the reward process all together can be very helpful."
      ],
      "id": "ygPUCdhan7Q9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMROMsDBn7Q-"
      },
      "source": [
        "\n",
        "\n",
        "## PettingZoo: interacting With Environments\n",
        "\n",
        "Environments can be interacted with using a similar interface to Gym:\n",
        "\n",
        "```{python}\n",
        "env.reset()\n",
        "for agent in env.agent_iter():\n",
        "    observation, reward, done, info = env.last()\n",
        "    action = policy(observation, agent)\n",
        "    env.step(action)\n",
        "```\n",
        "\n",
        "The commonly used methods are:\n",
        "\n",
        "`agent_iter(max_iter=2**63)` returns an **iterator** that yields the current agent of the environment. It terminates when all agents in the environment are done or when `max_iter` (steps have been executed).\n",
        "\n",
        "`last(observe=True)` returns `observation`, `reward`, `done`, and `info` for the agent currently able to act. The returned reward is the **cumulative reward** that the agent has received since it last acted. If observe is set to `False`, the observation will not be computed, and `None` will be returned in its place. Note that a single agent being done does not imply the environment is done.\n",
        "\n",
        "Code example:\n",
        "\n",
        "```{python}\n",
        "observation, reward, done, info = env.last()\n",
        "```\n",
        "\n",
        "`reset()` resets the environment and sets it up for use when called the first time. Only after calling this function do objects like `agents` become available.\n",
        "\n",
        "`step(action)` takes and executes the action of the agent in the environment, automatically switches control to the next agent.\n",
        "\n",
        "While developing code, several lower level methods I found useful.\n",
        "\n",
        "`agent_selection` displays the currently selected agent.\n",
        "\n",
        "`agents` list all available agents.\n",
        "\n",
        "The complete API including lower level functionality is at https://www.pettingzoo.ml/api\n",
        "\n"
      ],
      "id": "gMROMsDBn7Q-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUvNOpRFn7Q-"
      },
      "source": [
        "# Installing PettingZoo\n",
        "\n",
        "It is best to create a clean Python 3 virtual environment to run this notebook in. "
      ],
      "id": "RUvNOpRFn7Q-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmocSGCNn7Q_"
      },
      "source": [
        "```\n",
        "# create venv\n",
        "python3 -m venv marl-env\n",
        "# active venv\n",
        "source marl-env/bin/activate\n",
        "# upgrade really old pip version on my system\n",
        "pip install --upgrade pip\n",
        "# install packages\n",
        "pip install pettingzoo[classic]\n",
        "pip install spyder-notebook\n",
        "pip install dill\n",
        "```\n"
      ],
      "id": "UmocSGCNn7Q_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hx2UOfZ3oZTQ",
        "outputId": "f75c17a8-62db-43c3-df03-43c66d4a7ac5"
      },
      "source": [
        "!apt-get install python3.9-venv\n",
        "\n",
        "# create venv\n",
        "!python3 -m venv marl-env\n",
        "# active venv\n",
        "!source marl-env/bin/activate\n",
        "# upgrade really old pip version on my system\n",
        "!pip install --upgrade pip\n",
        "# install packages\n",
        "!pip install pettingzoo[classic]\n",
        "!pip install spyder-notebook\n",
        "!pip install dill"
      ],
      "id": "hx2UOfZ3oZTQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib python3.9 python3.9-distutils\n",
            "  python3.9-lib2to3 python3.9-minimal\n",
            "Suggested packages:\n",
            "  python3.9-doc binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.9-minimal libpython3.9-stdlib python3.9 python3.9-distutils\n",
            "  python3.9-lib2to3 python3.9-minimal python3.9-venv\n",
            "0 upgraded, 7 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 7,359 kB of archives.\n",
            "After this operation, 22.7 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.9-minimal amd64 3.9.9-1+bionic2 [789 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.9-minimal amd64 3.9.9-1+bionic2 [1,910 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.9-stdlib amd64 3.9.9-1+bionic2 [1,690 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.9 amd64 3.9.9-1+bionic2 [481 kB]\n",
            "Get:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.9-lib2to3 all 3.9.9-1+bionic2 [125 kB]\n",
            "Get:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.9-distutils all 3.9.9-1+bionic2 [190 kB]\n",
            "Get:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.9-venv amd64 3.9.9-1+bionic2 [2,174 kB]\n",
            "Fetched 7,359 kB in 5s (1,397 kB/s)\n",
            "Selecting previously unselected package libpython3.9-minimal:amd64.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.9-minimal_3.9.9-1+bionic2_amd64.deb ...\n",
            "Unpacking libpython3.9-minimal:amd64 (3.9.9-1+bionic2) ...\n",
            "Selecting previously unselected package python3.9-minimal.\n",
            "Preparing to unpack .../1-python3.9-minimal_3.9.9-1+bionic2_amd64.deb ...\n",
            "Unpacking python3.9-minimal (3.9.9-1+bionic2) ...\n",
            "Selecting previously unselected package libpython3.9-stdlib:amd64.\n",
            "Preparing to unpack .../2-libpython3.9-stdlib_3.9.9-1+bionic2_amd64.deb ...\n",
            "Unpacking libpython3.9-stdlib:amd64 (3.9.9-1+bionic2) ...\n",
            "Selecting previously unselected package python3.9.\n",
            "Preparing to unpack .../3-python3.9_3.9.9-1+bionic2_amd64.deb ...\n",
            "Unpacking python3.9 (3.9.9-1+bionic2) ...\n",
            "Selecting previously unselected package python3.9-lib2to3.\n",
            "Preparing to unpack .../4-python3.9-lib2to3_3.9.9-1+bionic2_all.deb ...\n",
            "Unpacking python3.9-lib2to3 (3.9.9-1+bionic2) ...\n",
            "Selecting previously unselected package python3.9-distutils.\n",
            "Preparing to unpack .../5-python3.9-distutils_3.9.9-1+bionic2_all.deb ...\n",
            "Unpacking python3.9-distutils (3.9.9-1+bionic2) ...\n",
            "Selecting previously unselected package python3.9-venv.\n",
            "Preparing to unpack .../6-python3.9-venv_3.9.9-1+bionic2_amd64.deb ...\n",
            "Unpacking python3.9-venv (3.9.9-1+bionic2) ...\n",
            "Setting up python3.9-lib2to3 (3.9.9-1+bionic2) ...\n",
            "Setting up libpython3.9-minimal:amd64 (3.9.9-1+bionic2) ...\n",
            "Setting up libpython3.9-stdlib:amd64 (3.9.9-1+bionic2) ...\n",
            "Setting up python3.9-minimal (3.9.9-1+bionic2) ...\n",
            "Setting up python3.9-distutils (3.9.9-1+bionic2) ...\n",
            "Setting up python3.9 (3.9.9-1+bionic2) ...\n",
            "Setting up python3.9-venv (3.9.9-1+bionic2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Error: Command '['/content/marl-env/bin/python3', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1.\n",
            "/bin/bash: marl-env/bin/activate: No such file or directory\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "Collecting pettingzoo[classic]\n",
            "  Downloading PettingZoo-1.14.0.tar.gz (756 kB)\n",
            "     |████████████████████████████████| 756 kB 5.2 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from pettingzoo[classic]) (1.19.5)\n",
            "Collecting gym>=0.21.0\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "     |████████████████████████████████| 1.5 MB 36.9 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting chess==1.7.0\n",
            "  Downloading chess-1.7.0-py3-none-any.whl (147 kB)\n",
            "     |████████████████████████████████| 147 kB 54.1 MB/s            \n",
            "\u001b[?25hCollecting rlcard==1.0.4\n",
            "  Downloading rlcard-1.0.4.tar.gz (256 kB)\n",
            "     |████████████████████████████████| 256 kB 57.4 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "     |████████████████████████████████| 18.3 MB 86 kB/s              \n",
            "\u001b[?25hCollecting hanabi_learning_environment==0.0.1\n",
            "  Downloading hanabi_learning_environment-0.0.1.tar.gz (72 kB)\n",
            "     |████████████████████████████████| 72 kB 898 kB/s             \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from hanabi_learning_environment==0.0.1->pettingzoo[classic]) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from rlcard==1.0.4->pettingzoo[classic]) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.21.0->pettingzoo[classic]) (1.3.0)\n",
            "Requirement already satisfied: importlib_metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym>=0.21.0->pettingzoo[classic]) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym>=0.21.0->pettingzoo[classic]) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=4.8.1->gym>=0.21.0->pettingzoo[classic]) (3.10.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->hanabi_learning_environment==0.0.1->pettingzoo[classic]) (2.21)\n",
            "Building wheels for collected packages: hanabi-learning-environment, rlcard, gym, pettingzoo\n",
            "  Building wheel for hanabi-learning-environment (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hanabi-learning-environment: filename=hanabi_learning_environment-0.0.1-cp37-cp37m-linux_x86_64.whl size=90669 sha256=f96aeffddc72270d136bd8e198bab687d3a3961e7591e4b054020fb9d059bc2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/24/f0/03904c208e8feef0005d5786df096e8e8eb7e128e5d988888b\n",
            "  Building wheel for rlcard (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rlcard: filename=rlcard-1.0.4-py3-none-any.whl size=307728 sha256=8af69477675826388157ac4b76c797aa6e27c921098ef634cb7af681e2112353\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/8d/3d/b288215812e51a5dd9ed0b7ec713b982d77f1173a8d691aebb\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616825 sha256=08610cd6676257e088fb90cfff3fb74bac160bb5ac5c7c5b7a4669ca022525e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "  Building wheel for pettingzoo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pettingzoo: filename=PettingZoo-1.14.0-py3-none-any.whl size=874226 sha256=9518f6f685ffaeb447549b26f499420ddbc6f2e14b4d6dc38c46544bb49bae94\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/a7/ad/c4d2a42ddfb4b6ceb16a0ca730ae46d8621233408522053338\n",
            "Successfully built hanabi-learning-environment rlcard gym pettingzoo\n",
            "Installing collected packages: gym, rlcard, pygame, pettingzoo, hanabi-learning-environment, chess\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed chess-1.7.0 gym-0.21.0 hanabi-learning-environment-0.0.1 pettingzoo-1.14.0 pygame-2.1.0 rlcard-1.0.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting spyder-notebook\n",
            "  Downloading spyder_notebook-0.3.2-py3-none-any.whl (1.7 MB)\n",
            "     |████████████████████████████████| 1.7 MB 5.4 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from spyder-notebook) (5.1.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from spyder-notebook) (4.9.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from spyder-notebook) (5.1.1)\n",
            "Collecting spyder<5,>=4.1\n",
            "  Downloading spyder-4.2.5-py3-none-any.whl (10.5 MB)\n",
            "     |████████████████████████████████| 10.5 MB 28.7 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from spyder-notebook) (2.23.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from spyder-notebook) (1.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spyder-notebook) (2.11.3)\n",
            "Requirement already satisfied: notebook>=4.3 in /usr/local/lib/python3.7/dist-packages (from spyder-notebook) (5.3.1)\n",
            "Collecting qdarkstyle\n",
            "  Downloading QDarkStyle-3.0.3-py2.py3-none-any.whl (450 kB)\n",
            "     |████████████████████████████████| 450 kB 62.4 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3->spyder-notebook) (0.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3->spyder-notebook) (4.10.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3->spyder-notebook) (0.12.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3->spyder-notebook) (1.8.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3->spyder-notebook) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3->spyder-notebook) (5.3.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.3->spyder-notebook) (5.6.1)\n",
            "Requirement already satisfied: chardet>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (3.0.4)\n",
            "Collecting jedi==0.17.2\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "     |████████████████████████████████| 1.4 MB 60.7 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (22.3.0)\n",
            "Requirement already satisfied: pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (2.6.1)\n",
            "Requirement already satisfied: pickleshare>=0.4 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (0.7.5)\n",
            "Requirement already satisfied: psutil>=5.3 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (5.4.8)\n",
            "Collecting pyqt5<5.13\n",
            "  Downloading PyQt5-5.12.3-5.12.10-cp35.cp36.cp37.cp38.cp39-abi3-manylinux1_x86_64.whl (62.4 MB)\n",
            "     |████████████████████████████████| 62.4 MB 1.2 MB/s             \n",
            "\u001b[?25hCollecting ipython>=7.6.0\n",
            "  Downloading ipython-7.30.1-py3-none-any.whl (791 kB)\n",
            "     |████████████████████████████████| 791 kB 51.4 MB/s            \n",
            "\u001b[?25hCollecting qdarkstyle\n",
            "  Downloading QDarkStyle-2.8.1-py2.py3-none-any.whl (217 kB)\n",
            "     |████████████████████████████████| 217 kB 61.1 MB/s            \n",
            "\u001b[?25hCollecting textdistance>=4.2.0\n",
            "  Downloading textdistance-4.2.2-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: qtconsole>=5.0.3 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (5.2.1)\n",
            "Collecting three-merge>=0.1.1\n",
            "  Downloading three_merge-0.1.1-py2.py3-none-any.whl (6.4 kB)\n",
            "Collecting pyxdg>=0.26\n",
            "  Downloading pyxdg-0.27-py2.py3-none-any.whl (49 kB)\n",
            "     |████████████████████████████████| 49 kB 3.3 MB/s             \n",
            "\u001b[?25hCollecting numpydoc>=0.6.0\n",
            "  Downloading numpydoc-1.1.0-py3-none-any.whl (47 kB)\n",
            "     |████████████████████████████████| 47 kB 4.6 MB/s             \n",
            "\u001b[?25hCollecting watchdog<2.0.0,>=0.10.3\n",
            "  Downloading watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl (72 kB)\n",
            "     |████████████████████████████████| 72 kB 941 kB/s             \n",
            "\u001b[?25hCollecting pyqtwebengine<5.13\n",
            "  Downloading PyQtWebEngine-5.12.1-5.12.10-cp35.cp36.cp37.cp38.cp39-abi3-manylinux1_x86_64.whl (60.1 MB)\n",
            "     |████████████████████████████████| 60.1 MB 1.2 MB/s             \n",
            "\u001b[?25hCollecting qtawesome>=0.5.7\n",
            "  Downloading QtAwesome-1.1.1-py3-none-any.whl (2.3 MB)\n",
            "     |████████████████████████████████| 2.3 MB 45.1 MB/s            \n",
            "\u001b[?25hCollecting python-language-server[all]<1.0.0,>=0.36.2\n",
            "  Downloading python_language_server-0.36.2-py2.py3-none-any.whl (51 kB)\n",
            "     |████████████████████████████████| 51 kB 441 kB/s             \n",
            "\u001b[?25hCollecting jsonschema>=3.2.0\n",
            "  Downloading jsonschema-4.2.1-py3-none-any.whl (69 kB)\n",
            "     |████████████████████████████████| 69 kB 6.3 MB/s             \n",
            "\u001b[?25hCollecting pylint>=1.0\n",
            "  Downloading pylint-2.12.2-py3-none-any.whl (414 kB)\n",
            "     |████████████████████████████████| 414 kB 52.6 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: pexpect>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (4.8.0)\n",
            "Collecting diff-match-patch>=20181111\n",
            "  Downloading diff_match_patch-20200713-py3-none-any.whl (61 kB)\n",
            "     |████████████████████████████████| 61 kB 230 kB/s             \n",
            "\u001b[?25hCollecting keyring>=17.0.0\n",
            "  Downloading keyring-23.4.0-py3-none-any.whl (33 kB)\n",
            "Collecting intervaltree>=3.0.2\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: atomicwrites>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (1.4.0)\n",
            "Collecting parso==0.7.0\n",
            "  Downloading parso-0.7.0-py2.py3-none-any.whl (100 kB)\n",
            "     |████████████████████████████████| 100 kB 8.5 MB/s            \n",
            "\u001b[?25hCollecting pyls-black>=0.4.6\n",
            "  Downloading pyls_black-0.4.7-py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: setuptools>=39.0.0 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (57.4.0)\n",
            "Collecting spyder-kernels<1.11.0,>=1.10.2\n",
            "  Downloading spyder_kernels-1.10.3-py2.py3-none-any.whl (65 kB)\n",
            "     |████████████████████████████████| 65 kB 3.5 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (1.3.0)\n",
            "Collecting pyls-spyder>=0.3.2\n",
            "  Downloading pyls_spyder-0.4.0-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: sphinx>=0.6.6 in /usr/local/lib/python3.7/dist-packages (from spyder<5,>=4.1->spyder-notebook) (1.8.6)\n",
            "Collecting helpdev>=0.6.10\n",
            "  Downloading helpdev-0.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spyder-notebook) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->spyder-notebook) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->spyder-notebook) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->spyder-notebook) (2021.10.8)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from helpdev>=0.6.10->qdarkstyle->spyder-notebook) (4.8.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3.0.2->spyder<5,>=4.1->spyder-notebook) (2.4.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.6.0->spyder<5,>=4.1->spyder-notebook) (0.1.3)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.6.0->spyder<5,>=4.1->spyder-notebook) (0.2.0)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.24-py3-none-any.whl (374 kB)\n",
            "     |████████████████████████████████| 374 kB 73.6 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.6.0->spyder<5,>=4.1->spyder-notebook) (4.4.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->spyder<5,>=4.1->spyder-notebook) (21.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->spyder<5,>=4.1->spyder-notebook) (0.18.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.2.0->spyder<5,>=4.1->spyder-notebook) (5.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook>=4.3->spyder-notebook) (2.8.2)\n",
            "Collecting SecretStorage>=3.2\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting jeepney>=0.4.2\n",
            "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
            "     |████████████████████████████████| 54 kB 2.5 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3->spyder-notebook) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3->spyder-notebook) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3->spyder-notebook) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3->spyder-notebook) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3->spyder-notebook) (0.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.3->spyder-notebook) (0.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>=4.4.0->spyder<5,>=4.1->spyder-notebook) (0.7.0)\n",
            "Collecting astroid<2.10,>=2.9.0\n",
            "  Downloading astroid-2.9.0-py3-none-any.whl (250 kB)\n",
            "     |████████████████████████████████| 250 kB 55.8 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from pylint>=1.0->spyder<5,>=4.1->spyder-notebook) (3.10.0.2)\n",
            "Collecting mccabe<0.7,>=0.6\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: toml>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from pylint>=1.0->spyder<5,>=4.1->spyder-notebook) (0.10.2)\n",
            "Collecting isort<6,>=4.2.5\n",
            "  Downloading isort-5.10.1-py3-none-any.whl (103 kB)\n",
            "     |████████████████████████████████| 103 kB 62.7 MB/s            \n",
            "\u001b[?25hCollecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.4.0-py3-none-any.whl (14 kB)\n",
            "Collecting black>=19.3b0\n",
            "  Downloading black-21.12b0-py3-none-any.whl (156 kB)\n",
            "     |████████████████████████████████| 156 kB 62.2 MB/s            \n",
            "\u001b[?25hCollecting python-lsp-server>=1.0.1\n",
            "  Downloading python_lsp_server-1.3.3-py3-none-any.whl (55 kB)\n",
            "     |████████████████████████████████| 55 kB 3.6 MB/s             \n",
            "\u001b[?25hCollecting PyQt5_sip<13,>=4.19.14\n",
            "  Downloading PyQt5_sip-12.9.0-cp37-cp37m-manylinux1_x86_64.whl (317 kB)\n",
            "     |████████████████████████████████| 317 kB 52.8 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: pluggy in /usr/local/lib/python3.7/dist-packages (from python-language-server[all]<1.0.0,>=0.36.2->spyder<5,>=4.1->spyder-notebook) (0.7.1)\n",
            "Collecting ujson>=3.0.0\n",
            "  Downloading ujson-4.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "     |████████████████████████████████| 216 kB 60.8 MB/s            \n",
            "\u001b[?25hCollecting python-jsonrpc-server>=0.4.0\n",
            "  Downloading python_jsonrpc_server-0.4.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting rope>=0.10.5\n",
            "  Downloading rope-0.22.0-py3-none-any.whl (185 kB)\n",
            "     |████████████████████████████████| 185 kB 60.2 MB/s            \n",
            "\u001b[?25hCollecting flake8>=3.8.0\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "     |████████████████████████████████| 64 kB 2.5 MB/s             \n",
            "\u001b[?25hCollecting autopep8\n",
            "  Downloading autopep8-1.6.0-py2.py3-none-any.whl (45 kB)\n",
            "     |████████████████████████████████| 45 kB 3.0 MB/s             \n",
            "\u001b[?25hCollecting pycodestyle<2.7.0,>=2.6.0\n",
            "  Downloading pycodestyle-2.6.0-py2.py3-none-any.whl (41 kB)\n",
            "     |████████████████████████████████| 41 kB 312 kB/s             \n",
            "\u001b[?25hCollecting pydocstyle>=2.0.0\n",
            "  Downloading pydocstyle-6.1.1-py3-none-any.whl (37 kB)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
            "     |████████████████████████████████| 185 kB 70.4 MB/s            \n",
            "\u001b[?25hCollecting pyflakes<2.3.0,>=2.2.0\n",
            "  Downloading pyflakes-2.2.0-py2.py3-none-any.whl (66 kB)\n",
            "     |████████████████████████████████| 66 kB 5.6 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (1.15.0)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (0.17.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (1.3.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (2.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (21.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (2.2.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (1.2.4)\n",
            "Collecting wurlitzer>=1.0.3\n",
            "  Downloading wurlitzer-3.0.2-py3-none-any.whl (7.3 kB)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.6.0-py3-none-any.whl (126 kB)\n",
            "     |████████████████████████████████| 126 kB 76.8 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook>=4.3->spyder-notebook) (1.0.0)\n",
            "Requirement already satisfied: argcomplete>=1.12.3 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook>=4.3->spyder-notebook) (1.12.3)\n",
            "Collecting typed-ast<2.0,>=1.4.0\n",
            "  Downloading typed_ast-1.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "     |████████████████████████████████| 843 kB 49.3 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: wrapt<1.14,>=1.11 in /usr/local/lib/python3.7/dist-packages (from astroid<2.10,>=2.9.0->pylint>=1.0->spyder<5,>=4.1->spyder-notebook) (1.13.3)\n",
            "Collecting lazy-object-proxy>=1.4.0\n",
            "  Downloading lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (55 kB)\n",
            "     |████████████████████████████████| 55 kB 3.6 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (2018.9)\n",
            "Requirement already satisfied: tomli<2.0.0,>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from black>=19.3b0->pyls-black>=0.4.6->spyder<5,>=4.1->spyder-notebook) (1.2.2)\n",
            "Collecting pathspec<1,>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black>=19.3b0->pyls-black>=0.4.6->spyder<5,>=4.1->spyder-notebook) (7.1.2)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting flake8>=3.8.0\n",
            "  Downloading flake8-4.0.0-py2.py3-none-any.whl (64 kB)\n",
            "     |████████████████████████████████| 64 kB 2.5 MB/s             \n",
            "\u001b[?25h  Downloading flake8-3.9.2-py2.py3-none-any.whl (73 kB)\n",
            "     |████████████████████████████████| 73 kB 1.7 MB/s             \n",
            "\u001b[?25h  Downloading flake8-3.9.1-py2.py3-none-any.whl (73 kB)\n",
            "     |████████████████████████████████| 73 kB 1.6 MB/s             \n",
            "\u001b[?25h  Downloading flake8-3.9.0-py2.py3-none-any.whl (73 kB)\n",
            "     |████████████████████████████████| 73 kB 1.4 MB/s             \n",
            "\u001b[?25h  Downloading flake8-3.8.4-py2.py3-none-any.whl (72 kB)\n",
            "     |████████████████████████████████| 72 kB 1.4 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->helpdev>=0.6.10->qdarkstyle->spyder-notebook) (3.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.6.0->spyder<5,>=4.1->spyder-notebook) (0.2.5)\n",
            "Collecting python-lsp-jsonrpc>=1.0.0\n",
            "  Downloading python_lsp_jsonrpc-1.0.0-py3-none-any.whl (8.5 kB)\n",
            "Collecting cryptography>=2.0\n",
            "  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "     |████████████████████████████████| 3.6 MB 43.3 MB/s            \n",
            "\u001b[?25hCollecting autopep8\n",
            "  Downloading autopep8-1.5.7-py2.py3-none-any.whl (45 kB)\n",
            "     |████████████████████████████████| 45 kB 2.8 MB/s             \n",
            "\u001b[?25h  Downloading autopep8-1.5.6-py2.py3-none-any.whl (44 kB)\n",
            "     |████████████████████████████████| 44 kB 2.8 MB/s             \n",
            "\u001b[?25h  Downloading autopep8-1.5.5-py2.py3-none-any.whl (44 kB)\n",
            "     |████████████████████████████████| 44 kB 2.3 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.3->spyder-notebook) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (3.0.6)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=0.6.6->spyder<5,>=4.1->spyder-notebook) (1.1.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=17.0.0->spyder<5,>=4.1->spyder-notebook) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=17.0.0->spyder<5,>=4.1->spyder-notebook) (2.21)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=cdfe8015ec2a42fb7662e134bf2331a97167253ae3967a3c6541ce6212579dfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: parso, ujson, typed-ast, prompt-toolkit, lazy-object-proxy, jedi, python-lsp-jsonrpc, python-jsonrpc-server, PyQt5-sip, pyflakes, pycodestyle, platformdirs, pathspec, mypy-extensions, mccabe, jsonschema, jeepney, isort, ipython, cryptography, astroid, yapf, wurlitzer, SecretStorage, rope, python-lsp-server, python-language-server, pyqt5, pylint, pydocstyle, ipykernel, helpdev, flake8, diff-match-patch, black, autopep8, watchdog, three-merge, textdistance, spyder-kernels, qtawesome, qdarkstyle, pyxdg, pyqtwebengine, pyls-spyder, pyls-black, numpydoc, keyring, intervaltree, spyder, spyder-notebook\n",
            "  Attempting uninstall: parso\n",
            "    Found existing installation: parso 0.8.3\n",
            "    Uninstalling parso-0.8.3:\n",
            "      Successfully uninstalled parso-0.8.3\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: jedi\n",
            "    Found existing installation: jedi 0.18.1\n",
            "    Uninstalling jedi-0.18.1:\n",
            "      Successfully uninstalled jedi-0.18.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.5.9 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.24 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.6.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.30.1 which is incompatible.\u001b[0m\n",
            "Successfully installed PyQt5-sip-12.9.0 SecretStorage-3.3.1 astroid-2.9.0 autopep8-1.5.5 black-21.12b0 cryptography-36.0.0 diff-match-patch-20200713 flake8-3.8.4 helpdev-0.7.1 intervaltree-3.1.0 ipykernel-6.6.0 ipython-7.30.1 isort-5.10.1 jedi-0.17.2 jeepney-0.7.1 jsonschema-4.2.1 keyring-23.4.0 lazy-object-proxy-1.6.0 mccabe-0.6.1 mypy-extensions-0.4.3 numpydoc-1.1.0 parso-0.7.0 pathspec-0.9.0 platformdirs-2.4.0 prompt-toolkit-3.0.24 pycodestyle-2.6.0 pydocstyle-6.1.1 pyflakes-2.2.0 pylint-2.12.2 pyls-black-0.4.7 pyls-spyder-0.4.0 pyqt5-5.12.3 pyqtwebengine-5.12.1 python-jsonrpc-server-0.4.0 python-language-server-0.36.2 python-lsp-jsonrpc-1.0.0 python-lsp-server-1.3.3 pyxdg-0.27 qdarkstyle-2.8.1 qtawesome-1.1.1 rope-0.22.0 spyder-4.2.5 spyder-kernels-1.10.3 spyder-notebook-0.3.2 textdistance-4.2.2 three-merge-0.1.1 typed-ast-1.5.1 ujson-4.3.0 watchdog-1.0.2 wurlitzer-3.0.2 yapf-0.31.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "ipykernel",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko__hNkKn7Q_"
      },
      "source": [
        "This installs [Spyder](https://www.spyder-ide.org/), the IDE I currently use for Python development, with the Notebook plugin to work both with Python scripts and Jupyter notebooks."
      ],
      "id": "ko__hNkKn7Q_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZlUMLr5n7RA"
      },
      "source": [
        "## PettingZoo TicTacToe environment\n",
        "\n",
        "\n",
        "\n",
        "The TicTacToe environment AEC diagram is depicted below:\n",
        "\n"
      ],
      "id": "HZlUMLr5n7RA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Kv4-g_n7RA"
      },
      "source": [
        "![](https://www.pettingzoo.ml/assets/img/aec/classic_tictactoe_aec.svg)"
      ],
      "id": "K8Kv4-g_n7RA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27mChIztn7RB"
      },
      "source": [
        "We start with loading the required libraries:"
      ],
      "id": "27mChIztn7RB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLtUQXJHn7RB"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import dill\n",
        "\n",
        "from pettingzoo.classic import tictactoe_v3"
      ],
      "id": "TLtUQXJHn7RB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8abjs_Pan7RD"
      },
      "source": [
        "We create an instance of a TicTacToe environment, call `reset()` to initialize the game and list the available agents (players):"
      ],
      "id": "8abjs_Pan7RD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydxp7x-dn7RD",
        "outputId": "e444a219-c0cd-4dc7-f747-44ab4eb9d51c"
      },
      "source": [
        "env = tictactoe_v3.env()\n",
        "\n",
        "env.reset()\n",
        "\n",
        "env.agents"
      ],
      "id": "ydxp7x-dn7RD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['player_1', 'player_2']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rn2PGiBn7RD"
      },
      "source": [
        "It helps to understand exactly how the PettingZoo \"mechanics\" work.\n",
        "\n",
        "Below we use the `agent_selection` method to show exactly when the active agent switches between the players:"
      ],
      "id": "0rn2PGiBn7RD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "t69r-4Pan7RE",
        "outputId": "0a0fc4b2-a7ee-44ea-c694-f8f75596194b"
      },
      "source": [
        "env.reset()\n",
        "env.agent_selection"
      ],
      "id": "t69r-4Pan7RE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'player_1'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CSolL9iDn7RE",
        "outputId": "8dfaaeb1-b821-467a-fa99-dec127ee7ac9"
      },
      "source": [
        "#env.step()\n",
        "# env acts by updating the observation and \n",
        "# switches to the next player\n",
        "env.agent_selection\n",
        "\n"
      ],
      "id": "CSolL9iDn7RE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'player_1'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "sBOe8HGFn7RF",
        "outputId": "796532d1-5f04-4abc-c3cb-4ec51b7bd3f8"
      },
      "source": [
        "# now player 2 can act\n",
        "env.step(1)\n",
        "env.agent_selection"
      ],
      "id": "sBOe8HGFn7RF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'player_2'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwNRth-rn7RF"
      },
      "source": [
        "So, directly after an agent takes an action using `env.step()`, the game moves on to the environent which \"acts\" by updating the board position, and after that the other player can act."
      ],
      "id": "uwNRth-rn7RF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddpDb31sn7RF"
      },
      "source": [
        "## Using action masks to choose from available actions\n",
        "\n",
        "The TicTacToe PettingZoo environment uses so-called \"action masks\"  to filter out actions that are invalid or not available given the current state of the environment. The action mask is part of the `observation` output from `last()`.\n"
      ],
      "id": "ddpDb31sn7RF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRUFradFTP_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "cb3c3452-fb44-4b89-a341-8e487dd8cc82"
      },
      "source": [
        "observation"
      ],
      "id": "YRUFradFTP_J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-16517b451208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'observation' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VxRwleBn7RF",
        "outputId": "3093a43d-ee65-4f11-b790-a6a3568883ca"
      },
      "source": [
        "observation, reward, done, info = env.last()\n",
        "\n",
        "observation['action_mask']"
      ],
      "id": "-VxRwleBn7RF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqaaCwVSn7RG"
      },
      "source": [
        "This mask tells us that for the current agent, actions `0` and `1` are not available.\n",
        "Our `policy()` function needs this information for action selection.\n",
        "\n",
        "If we choose an illegal action the environment throws an error message and terminates the current game:"
      ],
      "id": "rqaaCwVSn7RG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mkumlF7n7RG",
        "outputId": "2a2539f9-68a8-48ce-aed9-7b84f722b328"
      },
      "source": [
        "env.reset()\n",
        "# player 1\n",
        "env.step(0)\n",
        "# player 2 attempts same move\n",
        "env.step(0)\n"
      ],
      "id": "0mkumlF7n7RG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING]: Illegal move made, game terminating with current player losing. \n",
            "obs['action_mask'] contains a mask of all legal moves that can be chosen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WeVTsWTn7RG"
      },
      "source": [
        "If `done` is `True` , we can let the agent play action `None`. This allows the agents to keep on stepping until all rewards are received by all agents. \n",
        "\n",
        "For example this game where Player 1 plays the winning move:"
      ],
      "id": "6WeVTsWTn7RG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQOqfF_Nn7RG",
        "outputId": "61a47d89-1106-40c8-d7ed-85d95dd3d17a"
      },
      "source": [
        "env.reset()\n",
        "env.step(0)\n",
        "env.step(3)\n",
        "env.step(1)\n",
        "env.step(4)\n",
        "env.step(2)\n",
        "env.render()"
      ],
      "id": "lQOqfF_Nn7RG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     |     |     \n",
            "  X  |  O  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  X  |  O  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "     |     |     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDFu7bt_n7RG"
      },
      "source": [
        "Now the player is Player 2, that receives its (negative) reward for losing the game. Note that it cannot play any legal moves anymore because the game has ended, but we need to call `step()` with action `None` to move back to Player 1:"
      ],
      "id": "zDFu7bt_n7RG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3GlMCTjn7RH",
        "outputId": "abdfb413-3e4c-494b-db50-c14864570234"
      },
      "source": [
        "observation, reward, done, info = env.last()\n",
        "\n",
        "print(done)\n",
        "print(reward)\n",
        "\n",
        "env.step(None)"
      ],
      "id": "F3GlMCTjn7RH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPq1WnwZn7RH"
      },
      "source": [
        "Player 2 is removed from the list of available agents:"
      ],
      "id": "vPq1WnwZn7RH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw9vQZeKn7RH",
        "outputId": "b4d6d104-47bc-44a4-ef41-d0983f8ab0ae"
      },
      "source": [
        "env.agents"
      ],
      "id": "cw9vQZeKn7RH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['player_1']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtEGG1V4n7RH"
      },
      "source": [
        "Now player 1 can collect its reward for winning the game!"
      ],
      "id": "AtEGG1V4n7RH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkbUnwBsn7RH",
        "outputId": "be3b6e2e-4330-4372-ee8c-44be1483903a"
      },
      "source": [
        "observation, reward, done, info = env.last()\n",
        "\n",
        "print(done)\n",
        "print(reward)\n",
        "\n",
        "env.step(None)"
      ],
      "id": "qkbUnwBsn7RH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmK16-g3n7RI",
        "outputId": "62b96aad-a605-4032-855f-cfee5e7346e8"
      },
      "source": [
        "# no active agents anymore, need to call env.reset() to start a new game\n",
        "env.agents\n",
        "\n"
      ],
      "id": "LmK16-g3n7RI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "env.render()\n",
        "env.step(0)\n",
        "env.render()\n",
        "env.step(4)\n",
        "env.render()\n",
        "env.step(2)\n",
        "env.render()\n",
        "env.step(1)\n",
        "env.render()\n",
        "env.step(7)\n",
        "env.render()\n",
        "env.step(3)\n",
        "env.render()\n",
        "env.step(5)\n",
        "env.render()\n",
        "env.step(8)\n",
        "env.render()\n",
        "env.step(6)\n",
        "env.render()\n",
        "\n",
        "observation, reward, done, info = env.last()\n",
        "\n",
        "print(done)\n",
        "print(reward)\n",
        "\n",
        "env.step(None)\n",
        "\n",
        "observation, reward, done, info = env.last()\n",
        "\n",
        "print(done)\n",
        "print(reward)\n",
        "\n",
        "env.step(None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jcLkqRfJP6_",
        "outputId": "e408971c-2010-43cb-e614-be4dc49cdce1"
      },
      "id": "_jcLkqRfJP6_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     |     |     \n",
            "  -  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  -  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  -  |  -  |  -  \n",
            "     |     |     \n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  -  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  -  |  -  |  -  \n",
            "     |     |     \n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  -  |  O  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  -  |  -  |  -  \n",
            "     |     |     \n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  -  |  O  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "     |     |     \n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  O  |  O  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "     |     |     \n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  O  |  O  |  X  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "     |     |     \n",
            "     |     |     \n",
            "  X  |  O  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  O  |  O  |  X  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  X  |  -  |  -  \n",
            "     |     |     \n",
            "     |     |     \n",
            "  X  |  O  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  O  |  O  |  X  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  X  |  X  |  -  \n",
            "     |     |     \n",
            "     |     |     \n",
            "  X  |  O  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  O  |  O  |  X  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  X  |  X  |  O  \n",
            "     |     |     \n",
            "     |     |     \n",
            "  X  |  O  |  X  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  O  |  O  |  X  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  X  |  X  |  O  \n",
            "     |     |     \n",
            "True\n",
            "0\n",
            "True\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K-r5n2Mn7RI"
      },
      "source": [
        "# Exercise 1 Random play\n",
        "\n",
        "When two players who play completely randomly play Tic-Tac-Toe, the first player wins 58.49% of the time, the second player wins 28.81% of the time, and the game is a draw 12.70% of the time. \n",
        "\n",
        "Code up a function that has both players play a random policy for 10.000 games.\n",
        "Store the outcomes of the games (W/D/L) for both Players.\n",
        "Check your work by comparing with the percentages above.\n"
      ],
      "id": "-K-r5n2Mn7RI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SugwqF19n7RI",
        "outputId": "3f9f23b2-0f1b-41b0-aec7-9955d195ac99"
      },
      "source": [
        "# use this as starting point\n",
        "\n",
        "def policy(observation, agent):\n",
        "  action = random.choice(np.flatnonzero(observation['action_mask']))\n",
        "  return action\n",
        "\n",
        "env.reset()\n",
        "for agent in env.agent_iter():\n",
        "  observation, reward, done, info = env.last()\n",
        "  action = policy(observation, agent) if not done else None\n",
        "  env.step(action)\n",
        "  print(reward)\n",
        "  # env.render() # this visualizes a single game\n"
      ],
      "id": "SugwqF19n7RI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "-1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-zq4zEkqHa-"
      },
      "source": [
        "## Play random for 10 000 games & store outcomes"
      ],
      "id": "K-zq4zEkqHa-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmaJGavLqGB2",
        "outputId": "298f63c7-b951-4e2f-a350-35dde87bf76a"
      },
      "source": [
        "outcomes = {\"player_1\" : 0., \"player_2\" : 0.}\n",
        "for i in range(10000):\n",
        "  env.reset()\n",
        "  for agent in env.agent_iter():\n",
        "    observation, reward, done, info = env.last()\n",
        "    action = policy(observation, agent) if not done else None\n",
        "    outcomes[env.agent_selection] += max(reward, 0)\n",
        "    env.step(action)\n",
        "p1 = outcomes[\"player_1\"]/100\n",
        "p2 =outcomes[\"player_2\"]/100\n",
        "draw =0.01*(10000 - outcomes[\"player_1\"] - outcomes[\"player_2\"])\n",
        "print(\"The first player wins\", p1,\"% of the time, the second player wins\", p2,\"% of the time, and the game is a draw\", draw,\"% of the time. \")"
      ],
      "id": "vmaJGavLqGB2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first player wins 57.57 % of the time, the second player wins 29.74 % of the time, and the game is a draw 12.69 % of the time. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG6hgoasn7RJ"
      },
      "source": [
        "# Hashing the board position to a key for use in a dictionary"
      ],
      "id": "QG6hgoasn7RJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZwamXrTn7RJ"
      },
      "source": [
        "In the TicTacToe environment, observations of agents consist of a complete description of the board position. An observation of the board is a 3D array and looks like this:"
      ],
      "id": "7ZwamXrTn7RJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhN-Q4G7n7RJ",
        "outputId": "6be3ff66-a162-47f2-b80c-5120bdc26c72"
      },
      "source": [
        "env.reset()\n",
        "observation, reward, done, info = env.last()\n",
        "\n",
        "\n",
        "observation['observation']"
      ],
      "id": "NhN-Q4G7n7RJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp6j6Ac8n7RJ"
      },
      "source": [
        "Compare this to the properly rendered board position:"
      ],
      "id": "Gp6j6Ac8n7RJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMQE_r3wn7RJ",
        "outputId": "6cbe897a-1b6d-4e7a-f1c9-8004fcc3327c"
      },
      "source": [
        "env.render()"
      ],
      "id": "UMQE_r3wn7RJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     |     |     \n",
            "  -  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  -  |  -  |  -  \n",
            "_____|_____|_____\n",
            "     |     |     \n",
            "  -  |  -  |  -  \n",
            "     |     |     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FiVwhj8n7RJ"
      },
      "source": [
        "For Q-learning, we need the environment to store Q-values for each unique board position. A convenient way to create unique identifiers for all board positions is to use a **hash-function**.\n",
        "\n",
        "We encountered this concept at the beginning of the course:\n",
        "\n",
        ">*Hash functions* are used to transform a large amount of data (such as a complete board position aka game state) into a single number.\n",
        "The special thing about hash functions is that every board position is transformed into a unique number, i.e. there are no two board positions that are transformed to the same unique number.\n",
        "This allows us to use this to label / identify each board position, and use this as an identifier to store information about that board position.\n",
        "\n",
        "Example code (first convert observation to string, then hash):"
      ],
      "id": "3FiVwhj8n7RJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px_gJZn5n7RK",
        "outputId": "632ba4d9-3e9c-44da-b985-90c2474a8261"
      },
      "source": [
        "state = hash(str(observation['observation']))\n",
        "\n",
        "state"
      ],
      "id": "Px_gJZn5n7RK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-582640870111660086"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_AfhRJLn7RK"
      },
      "source": [
        "**Update:** \n",
        "I discovered that in Python 3, the `hash()` function is, by design, not reproducible between python sessions! This makes it unsuitable for our purpose, since we want to learn an optimal policy for each state, and save that policy (the Q-table) to disk for later use. \n",
        "This later use will consist of things like testing the policy's performance, or as an AI player to play against ourselves.\n",
        "\n",
        "To have reproducible hashing we can use `hashlib`, a Python library containing various hashing algorithms. I chose the `MD5` algorithm:"
      ],
      "id": "k_AfhRJLn7RK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2hI_Gblmn7RK",
        "outputId": "1fff130a-4f3c-4bae-be8c-f7365e02216e"
      },
      "source": [
        "import hashlib\n",
        "\n",
        "def encode_state(observation):\n",
        "    # encode observation as bytes           \n",
        "    obs_bytes = str(observation).encode('utf-8')\n",
        "    # create md5 hash\n",
        "    m = hashlib.md5(obs_bytes)\n",
        "    # return hash as hex digest\n",
        "    state = m.hexdigest()\n",
        "    return(state)\n",
        "\n",
        "encode_state(observation['observation'])"
      ],
      "id": "2hI_Gblmn7RK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'65ea394aefe804468cc42b20ecc8b606'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6lbjElBn7RL"
      },
      "source": [
        "To make self-play (An single agent that plays against itself) easy to implement, in PettingZoo the observation contains information about which player is making the observation. This information is encoded in the observation by flipping the board position player index order (aka \"inverting the channels\").\n",
        "\n",
        "Take for example the observation of the board state after Player 1 made a first move:"
      ],
      "id": "e6lbjElBn7RL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvdFUBFon7RL",
        "outputId": "0d5b7936-b816-4bb6-f28b-ea95d06acfd7"
      },
      "source": [
        "env = tictactoe_v3.env()\n",
        "env.reset()\n",
        "env.step(4)\n",
        "env.observe('player_1')['observation']"
      ],
      "id": "UvdFUBFon7RL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [1, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX04yr2Pn7RM"
      },
      "source": [
        "Now compare this with how Player 2 observes the same board position:"
      ],
      "id": "SX04yr2Pn7RM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKpUWUapn7RM",
        "outputId": "39cfb8ee-626f-4141-9413-6de5279b2899"
      },
      "source": [
        "env.observe('player_2')['observation']"
      ],
      "id": "UKpUWUapn7RM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 1],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtFSVZDtn7RM"
      },
      "source": [
        "In practice, this is only an issue if both players see the same board position, which only occurs at the end of a game, when the players collect their rewards. "
      ],
      "id": "DtFSVZDtn7RM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBF0O91zn7RM",
        "outputId": "e09eb2fe-dc54-453b-ed01-7c939cabf146"
      },
      "source": [
        "env = tictactoe_v3.env()\n",
        "env.reset()\n",
        "env.step(0)\n",
        "env.step(6)\n",
        "env.step(1)\n",
        "env.step(5)\n",
        "env.step(2)\n",
        "\n",
        "env.observe(\"player_1\")['observation']"
      ],
      "id": "HBF0O91zn7RM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[0, 1],\n",
              "        [0, 0],\n",
              "        [0, 0]]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51vy9RDun7RN",
        "outputId": "b79bd79b-6dac-487f-9e83-4e133ab0974f"
      },
      "source": [
        "env.step(None)\n",
        "env.observe(\"player_2\")['observation']"
      ],
      "id": "51vy9RDun7RN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[0, 0],\n",
              "        [0, 0],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sPz6son7RN"
      },
      "source": [
        "To avoid double counting of end-game board positions, I used this trick:"
      ],
      "id": "C_sPz6son7RN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H64smzFdn7RO",
        "outputId": "302b9bc0-030e-4dd1-fc83-9ff6fa918b22"
      },
      "source": [
        "state = encode_state(env.render(mode = 'ansi'))\n",
        "\n",
        "state"
      ],
      "id": "H64smzFdn7RO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'6c2e7780c70c674fc2c99fb84f81de15'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdQUTnoqn7RO"
      },
      "source": [
        "# Exercise 2 Hashing and dictionaries for the Q-table\n",
        "\n",
        "For this exercise, adapt your code from Exercise 1 to add a  `defaultdict` dictionary that contains the value `0` for each board position (identified using `encode_state()` ) the agents encounter. \n",
        "\n",
        "Run your code for 20.000 games with the agents playing a random policy to find out how many distinct states Tic-Tac-Toe contains. The dictionary should max out at 5478 different states.\n",
        "\n",
        "You can use the code provided below."
      ],
      "id": "EdQUTnoqn7RO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmohRNsAn7RO"
      },
      "source": [
        "from collections import defaultdict\n",
        "def example():\n",
        "  env.reset()\n",
        "\n",
        "  Q = defaultdict(lambda: np.zeros(nA)) \n",
        "\n",
        "  # reminder about how default dict works\n",
        "\n",
        "  Q['32433'] = 0\n",
        "  Q['-5323'] = 0\n",
        "  Q['2397887'] = 0\n",
        "\n",
        "  Q\n",
        "example()"
      ],
      "id": "GmohRNsAn7RO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPUFjOm8EazQ",
        "outputId": "3785cb77-9485-4fbb-8455-24de3f25954d"
      },
      "source": [
        "Q = defaultdict()\n",
        "# Q['32433'] = 0\n",
        "# Q['-5323'] = 0\n",
        "# Q['2397887'] = 0\n",
        "print(Q) \n",
        "Q_list = []\n",
        "for i in range(20000):\n",
        "  env.reset()\n",
        "  for agent in env.agent_iter():\n",
        "    observation, reward, done, info = env.last()\n",
        "    action = policy(observation, agent) if not done else None\n",
        "    # outcomes[env.agent_selection] += max(reward, 0)\n",
        "    state = encode_state(env.render(mode = 'ansi'))\n",
        "    Q[state] = 0\n",
        "    env.step(action)\n",
        "  Q_list.append(len(Q))\n",
        "print(len(Q))"
      ],
      "id": "JPUFjOm8EazQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {})\n",
            "5478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ci dessous le nombre d'états trouvés au cours des 20 000 parties."
      ],
      "metadata": {
        "id": "Jf-CKSgEkWXl"
      },
      "id": "Jf-CKSgEkWXl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "wnK4ybPTlP8V",
        "outputId": "31dcb6d6-e6cb-4f18-ac73-96d2314c6edd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([i for i in range(20_000)], Q_list)"
      ],
      "id": "wnK4ybPTlP8V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5223eb2ad0>]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfJfk9NGn7RO"
      },
      "source": [
        "## License\n",
        "\n",
        "The code in this notebook is copyrighted by Gertjan Verhoeven and licensed under the new BSD (3-clause) license:\n",
        "\n",
        "https://opensource.org/licenses/BSD-3-Clause\n",
        "\n",
        "The text and figures in this notebook (if any) are copyrighted by Gertjan Verhoeven and licensed under the CC BY-NC 4.0 license:\n",
        "\n",
        "https://creativecommons.org/licenses/by-nc/4.0/"
      ],
      "id": "KfJfk9NGn7RO"
    }
  ]
}